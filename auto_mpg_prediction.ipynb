{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto MPG prediction\n",
    "\n",
    "#### Install required versions of Sagemaker SDK and Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.7/site-packages (0.1.39)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker-experiments) (1.24.62)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.62 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.27.62)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3>=1.16.27->sagemaker-experiments) (1.26.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.62->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sagemaker>=2.15\n",
    "%pip install sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intiailize Sagemaker session and Sagemaker boto3 client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default bucket:  sagemaker-us-east-1-392525434032\n",
      "Using  Region:  us-east-1\n",
      "Using execution Role:  arn:aws:iam::392525434032:role/service-role/AmazonSageMaker-ExecutionRole-20220310T175822\n"
     ]
    }
   ],
   "source": [
    "# initialize sagemaker session \n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket() \n",
    "role = get_execution_role()\n",
    "\n",
    "# boto3 client\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "print(\"Using default bucket: \", bucket)\n",
    "print(\"Using  Region: \", region)\n",
    "print(\"Using execution Role: \", role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define S3 bucket prefixes for Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"auto_mpg\"\n",
    "\n",
    "# raw data path\n",
    "raw_train_prefix = f\"{prefix}/data/bronze/train\"\n",
    "raw_val_prefix = f\"{prefix}/data/bronze/val\"\n",
    "raw_test_prefix = f\"{prefix}/data/bronze/test\"\n",
    "\n",
    "# preprocessed features path\n",
    "pp_train_prefix = f\"{prefix}/data/gold/train\"\n",
    "pp_val_prefix = f\"{prefix}/data/gold/val\"\n",
    "pp_test_prefix = f\"{prefix}/data/gold/test\"\n",
    "\n",
    "# preprocessor and ml models\n",
    "pp_model_prefix = f\"{prefix}/models/preprocessor\"\n",
    "ml_model_prefix = f\"{prefix}/models/ml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload Raw Data to S3\n",
    "\n",
    "In this step we perform the following\n",
    "1. Download the Raw Data\n",
    "2. Split it into train and test\n",
    "3. Upload to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-15 12:32:46--  https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 30286 (30K) [application/x-httpd-php]\n",
      "Saving to: ‘auto-mpg.data.2’\n",
      "\n",
      "auto-mpg.data.2     100%[===================>]  29.58K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-10-15 12:32:46 (457 KB/s) - ‘auto-mpg.data.2’ saved [30286/30286]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_raw_data_to_s3(sess, file_name=\"auto-mpg.data\", split=0.8):\n",
    "    \"\"\"\n",
    "    Read MPG dataset, peform train test split, then upload to s3\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    data = pd.read_csv(file_name, header = None, delimiter = '\\s+', low_memory = False, na_values = \"?\")\n",
    "    data_frame = data.drop(columns = 8)\n",
    "    data_frame = data_frame.fillna(data_frame.mean())\n",
    "    data_frame = data_frame.rename(index = int, columns = {0: \"mpg\", 1:\"cylinders\", 2: \"displacement\",3: \"horsepower\", 4: \"weight\", 5:\"acceleration\",6:\"model year\",7:\"origin\"})\n",
    "    \n",
    "    # train - test - split\n",
    "    train_df = data_frame.sample(frac=split)\n",
    "    test_df = data_frame.drop(train_df.index)\n",
    "    \n",
    "    val_df = test_df[:-10]\n",
    "    test_df = test_df[-10:]\n",
    "    \n",
    "    assert set(list(train_df.index)).intersection(list(test_df.index)) == set([]), \"overlap between train and test\"\n",
    "    \n",
    "    # upload data to s3\n",
    "    train_df.to_csv(\"train.csv\", index=False, sep=',', encoding='utf-8')\n",
    "    train_path = sess.upload_data(path=\"train.csv\", bucket=bucket, key_prefix=raw_train_prefix)\n",
    "    \n",
    "    val_df.to_csv(\"val.csv\", index=False, sep=',', encoding='utf-8')\n",
    "    val_path = sess.upload_data(path=\"val.csv\", bucket=bucket, key_prefix=raw_val_prefix)\n",
    "    \n",
    "    test_df.to_csv(\"test.csv\", index=False, sep=',', encoding='utf-8')\n",
    "    test_path = sess.upload_data(path=\"test.csv\", bucket=bucket, key_prefix=raw_test_prefix)\n",
    "    \n",
    "    os.remove(\"train.csv\")\n",
    "    os.remove(\"val.csv\")\n",
    "    os.remove(\"test.csv\")\n",
    "    \n",
    "    return train_path, val_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw train path: s3://sagemaker-us-east-1-392525434032/auto_mpg/data/bronze/train/train.csv\n",
      "raw val path: s3://sagemaker-us-east-1-392525434032/auto_mpg/data/bronze/val/val.csv\n",
      "raw test path: s3://sagemaker-us-east-1-392525434032/auto_mpg/data/bronze/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_path, val_path, test_path = upload_raw_data_to_s3(sess)\n",
    "print(\"raw train path:\", train_path)\n",
    "print(\"raw val path:\", val_path)\n",
    "print(\"raw test path:\", test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  autompg-feature-eng-2022-10-15-12-56-04-718\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/auto_mpg/data/bronze/train', 'LocalPath': '/opt/ml/processing/input/train', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/auto_mpg/data/bronze/val', 'LocalPath': '/opt/ml/processing/input/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/autompg-feature-eng-2022-10-15-12-56-04-718/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_features', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/auto_mpg/data/gold/train', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'val_features', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/auto_mpg/data/gold/val', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'preprocessor_model', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-392525434032/auto_mpg/models/preprocessor', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\n",
      ".."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "def get_s3_path(pth, bucket=bucket):\n",
    "    \"\"\" get full path in s3 \"\"\"\n",
    "    return f\"s3://{bucket}/{pth}\"\n",
    "\n",
    "\n",
    "current_time = datetime.now().strftime(\"%d-%b-%Y-%H:%M:%S\")\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    base_job_name=\"auto-mpg-feature-eng\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocess.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=get_s3_path(raw_train_prefix), destination=\"/opt/ml/processing/input/train\"),\n",
    "        ProcessingInput(source=get_s3_path(raw_val_prefix), destination=\"/opt/ml/processing/input/test\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_features\", source=\"/opt/ml/processing/train\", destination=get_s3_path(pp_train_prefix)),\n",
    "        ProcessingOutput(output_name=\"val_features\", source=\"/opt/ml/processing/test\", destination=get_s3_path(pp_val_prefix)),\n",
    "        ProcessingOutput(output_name=\"preprocessor_model\", source=\"/opt/ml/processing/output\", destination=get_s3_path(pp_model_prefix)),\n",
    "    ],\n",
    "    arguments=[\"--train-filename\", \"train.csv\", \"--test-filename\", \"val.csv\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-392525434032/auto_mpg/models/preprocessor/pl.joblib'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_config = sklearn_processor.jobs[-1].describe()['ProcessingOutputConfig']['Outputs']\n",
    "pp_model_path = output_config[2]['S3Output']['S3Uri'] + '/pl.joblib'\n",
    "pp_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Experiment, Trial and Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SKLearn Model\n",
    "\n",
    "Train Model in Script Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir(pth):\n",
    "    \"\"\" get the directory name of path \"\"\"\n",
    "    return \"/\".join(pth.split(\"/\")[:-1])\n",
    "\n",
    "\n",
    "\n",
    "train_path = get_dir(train_path)\n",
    "val_path = get_dir(val_path)\n",
    "test_path = get_dir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_path)\n",
    "print(val_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "auto_experiment = Experiment.create(experiment_name = \"auto-experiment-{}\".format(create_date),\n",
    "                                    description = \"auto experiment\",\n",
    "                                    tags = [{'Key': 'auto-experiment', 'Value': 'demo1'}])\n",
    "\n",
    "\n",
    "demo_trial = Trial.create(trial_name = \"auto-trial-{}\".format(create_date),\n",
    "                          experiment_name = auto_experiment.experiment_name,\n",
    "                          sagemaker_boto_client=sm_client,\n",
    "                          tags = [{'Key': 'auto-trial', 'Value': 'demo1'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"1.0-1\"\n",
    "script_path = \"model.py\"\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters={\"n_estimators\": 2},\n",
    "    tags=[{'Key': 'auto', 'Value': 'demo1'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.fit({\"train\": train_path}, experiment_config = {\n",
    "                \"TrialName\" : demo_trial.trial_name,\n",
    "                \"TrialComponentDisplayName\" : \"TrainingJob\",\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.5\n",
    "test_loss = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Training-Evaluation\", sagemaker_boto_client=sm_client) as tracker:\n",
    "    tracker.log_parameters(\n",
    "        {\n",
    "            \"train-mse-loss\": train_loss,\n",
    "            \"test-mse-loss\": test_loss ,\n",
    "        }\n",
    "    )\n",
    "    tracker.log_input(name=\"auto\", media_type=\"s3/uri\", value=get_dir(train_path))\n",
    "\n",
    "demo_trial.add_trial_component(tracker.trial_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "target = 'mpg'\n",
    "original_features = ['cylinders',\n",
    "                     'displacement',\n",
    "                     'horsepower',\n",
    "                     'weight',\n",
    "                     'acceleration',\n",
    "                     'model year',\n",
    "                     'origin']\n",
    "\n",
    "\n",
    "class CustomFeaturePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This is a custom transformer class that does the following\n",
    "    \n",
    "        1. converts model year to age\n",
    "        2. converts data type of categorical columns\n",
    "    \"\"\"\n",
    "    \n",
    "    feat = original_features\n",
    "    new_datatypes = {'cylinders': 'category', 'origin': 'category'}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Fit function\"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\" Transform Dataset \"\"\"\n",
    "        assert set(list(X.columns)) - set(list(self.feat))\\\n",
    "                    ==  set([]), \"input does have the right features\"\n",
    "        \n",
    "        # conver model year to age\n",
    "        X[\"model year\"] = 82 - X[\"model year\"]\n",
    "        \n",
    "        # change data types of cylinders and origin \n",
    "        X = X.astype(self.new_datatypes)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\" Fit transform function \"\"\"\n",
    "        x = self.fit(X)\n",
    "        x = self.transform(X)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# one hot categorical features\n",
    "# apply standard scaler to numerical features\n",
    "ct = ColumnTransformer([(\"categorical-feats\", OneHotEncoder(), make_column_selector(dtype_include=\"category\")),\n",
    "                        (\"numerical-feats\", StandardScaler(), make_column_selector(dtype_exclude=\"category\"))])\n",
    "\n",
    "# apply custom preprocessing\n",
    "pl = Pipeline([(\"custom-preprocessing\", CustomFeaturePreprocessor()), (\"column-preprocessing\", ct)])\n",
    "\n",
    "train_data = train_df.iloc[:, 1:]\n",
    "train_target = train_df[\"mpg\"].values.reshape(-1, 1)\n",
    "\n",
    "a = pl.fit_transform(train_data)\n",
    "\n",
    "\n",
    "def save_numpy(np_array, path):\n",
    "    \"\"\" save np array \"\"\"\n",
    "    with open(path, 'wb') as f:\n",
    "        np.save(f, np_array)\n",
    "        \n",
    "#save_numpy(a, \"a.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([train_target, a], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-Oct-2022-12:52:45\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime(\"%d-%b-%Y-%H:%M:%S\")\n",
    "print(timestampStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
